{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Copyright **`(c)`** 2022 Giovanni Squillero `<squillero@polito.it>`  \n",
    "[`https://github.com/squillero/computational-intelligence`](https://github.com/squillero/computational-intelligence)  \n",
    "Free for personal or classroom use; see [`LICENSE.md`](https://github.com/squillero/computational-intelligence/blob/master/LICENSE.md) for details.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from collections import namedtuple\n",
    "import random\n",
    "from typing import Callable\n",
    "from copy import deepcopy\n",
    "from itertools import accumulate\n",
    "from operator import xor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The *Nim* and *Nimply* classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nimply = namedtuple(\"Nimply\", \"row, num_objects\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Nim:\n",
    "    def __init__(self, num_rows: int, k: int = None) -> None: #k is the max number of object that can be removed from a line\n",
    "        self._rows = [i * 2 + 1 for i in range(num_rows)]\n",
    "        self._k = k\n",
    "\n",
    "    def __bool__(self):\n",
    "        return sum(self._rows) > 0\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"<\" + \" \".join(str(_) for _ in self._rows) + \">\"\n",
    "\n",
    "    @property\n",
    "    def rows(self) -> tuple:\n",
    "        return tuple(self._rows)\n",
    "\n",
    "    @property\n",
    "    def k(self) -> int:\n",
    "        return self._k\n",
    "\n",
    "    def print_state(self):\n",
    "        index = 0\n",
    "        res = \"\"\n",
    "        for row in self.rows:\n",
    "            res = res + str(index) + \":\" + str(row) + \" \"\n",
    "        return res\n",
    "        \n",
    "    def nimming(self, ply: Nimply) -> None:\n",
    "        row, num_objects = ply\n",
    "        assert self._rows[row] >= num_objects\n",
    "        assert self._k is None or num_objects <= self._k\n",
    "        self._rows[row] -= num_objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nim_sum(state: Nim) -> int:\n",
    "    *_, result = accumulate(state.rows, xor)\n",
    "    return result\n",
    "\n",
    "\n",
    "def cook_status(state: Nim) -> dict:\n",
    "    cooked = dict()\n",
    "    cooked[\"possible_moves\"] = [\n",
    "        (r, o) for r, c in enumerate(state.rows) for o in range(1, c + 1) if state.k is None or o <= state.k\n",
    "    ]\n",
    "    cooked[\"active_rows_number\"] = sum(o > 0 for o in state.rows)\n",
    "    cooked[\"shortest_row\"] = min((x for x in enumerate(state.rows) if x[1] > 0), key=lambda y: y[1])[0]\n",
    "    cooked[\"longest_row\"] = max((x for x in enumerate(state.rows)), key=lambda y: y[1])[0]\n",
    "    cooked[\"nim_sum\"] = nim_sum(state)\n",
    "\n",
    "    brute_force = list()\n",
    "    for m in cooked[\"possible_moves\"]:\n",
    "        tmp = deepcopy(state)\n",
    "        tmp.nimming(m)\n",
    "        brute_force.append((m, nim_sum(tmp)))\n",
    "    cooked[\"brute_force\"] = brute_force\n",
    "\n",
    "    return cooked"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample (and silly) startegies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pure_random(state: Nim) -> Nimply:\n",
    "    row = random.choice([r for r, c in enumerate(state.rows) if c > 0])\n",
    "    num_objects = random.randint(1, state.rows[row])\n",
    "    return Nimply(row, num_objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gabriele(state: Nim) -> Nimply:\n",
    "    \"\"\"Pick always the maximum possible number of the lowest row\"\"\"\n",
    "    possible_moves = [(r, o) for r, c in enumerate(state.rows) for o in range(1, c + 1)]\n",
    "    return Nimply(*max(possible_moves, key=lambda m: (-m[0], m[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimal_strategy(state: Nim) -> Nimply:\n",
    "    data = cook_status(state)\n",
    "    return next((bf for bf in data[\"brute_force\"] if bf[1] == 0), random.choice(data[\"brute_force\"]))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enrico(state: Nim) -> Nimply: #my strategy\n",
    "    data = cook_status(state)\n",
    "    if data[\"active_rows_number\"] == 0:\n",
    "        return (data[\"longest_row\"], state._rows[data[\"longest_row\"]])\n",
    "    else:\n",
    "        return (data[\"shortest_row\"], state._rows[data[\"shortest_row\"]])     "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>agent using reinforcement learning</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent():\n",
    "    def __init__(self, nim: Nim, num_tot_matches):\n",
    "        self.nim = nim          #to be update at each game\n",
    "        self.random_factor = 1  #at the begining is set to 1 -> 100 explore\n",
    "        self.learned = dict()    #key is the nim status (nim._rows) the value is a dict of ( key: ply, value: score) from previus games\n",
    "        self.current_move = dict()  #key is the nim status, value is the ply performed in the current game\n",
    "        self.num_matches = 0\n",
    "        self.num_tot_matched = num_tot_matches\n",
    "\n",
    "    def play(self) -> Nimply:  #return a move\n",
    "        selected_ply = None\n",
    "        if random.random() > self.random_factor: # exploitation: select best move in same status situation if exists(score must be grater that 0)\n",
    "            if self.nim.print_state() in self.learned.keys():\n",
    "                moves = self.learned[self.nim.print_state()]\n",
    "                best = None\n",
    "                max = 0\n",
    "                for move, score in moves.items():\n",
    "                    if score > max:\n",
    "                        \n",
    "                        best = move\n",
    "                        max = score\n",
    "                        \n",
    "                if best == None:\n",
    "                    selected_ply = pure_random(self.nim)\n",
    "                else:\n",
    "                    selected_ply = best\n",
    "                    \n",
    "            else:\n",
    "                selected_ply = pure_random(self.nim)       \n",
    "        else:   #exploration\n",
    "            selected_ply = pure_random(self.nim) \n",
    "        \n",
    "        self.current_move[self.nim.print_state()] = selected_ply\n",
    "        \n",
    "        return selected_ply\n",
    "\n",
    "    def update_score(self, win):    #in learned update score +1 if agent wins or -1 if loses\n",
    "        self.random_factor = 1 -2*(self.num_matches/self.num_tot_matched) #update random factor for encrease the exploitation the matches prograssion\n",
    "\n",
    "        for nim_state, move in self.current_move.items():\n",
    "            if nim_state in self.learned.keys():    \n",
    "                if move in self.learned[nim_state].keys():\n",
    "                    if win:\n",
    "                        self.learned[nim_state][move]+=1\n",
    "                    else:\n",
    "                        self.learned[nim_state][move]-=1\n",
    "                else:\n",
    "                    if win:\n",
    "                        self.learned[nim_state][move] = 1\n",
    "                    else:\n",
    "                        self.learned[nim_state][move] = -1\n",
    "            else:\n",
    "                if win:\n",
    "                    self.learned[nim_state] = {move: 1}\n",
    "                else:\n",
    "                    self.learned[nim_state] = {move: -1}\n",
    "                   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_MATCHES_EVAL = 100\n",
    "NIM_SIZE = 5\n",
    "NUM_MATCHES_TRAINING = 5000\n",
    "OPPONENT_TRAIN = [pure_random, enrico, gabriele, optimal_strategy]\n",
    "OPPONENT_EVAL = enrico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(robot):\n",
    "    won=0\n",
    "    last_player_start = 1\n",
    "    for i in range(NUM_MATCHES_TRAINING):\n",
    "        nim = Nim(NIM_SIZE)\n",
    "        robot.nim = nim\n",
    "        robot.num_matches = i\n",
    "        player = 1 - last_player_start  #for switching the starter\n",
    "        last_player_start = player\n",
    "        while nim:\n",
    "            if player == 0:\n",
    "                ply = OPPONENT_TRAIN[int(i//(NUM_MATCHES_TRAINING/len(OPPONENT_TRAIN)))](nim)  #select opponent starting from the silliest\n",
    "            else:\n",
    "                ply = robot.play()\n",
    "            nim.nimming(ply)\n",
    "            player = 1 - player\n",
    "        if player == 0: #robot win\n",
    "            won+=1\n",
    "            robot.update_score(1)\n",
    "        else:   #robot lose\n",
    "            robot.update_score(0)\n",
    "    print(\"won in training: \", won)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(robot) -> float:\n",
    "    won = 0\n",
    "    last_player_start = 1\n",
    "    for m in range(NUM_MATCHES_EVAL):\n",
    "        nim = Nim(NIM_SIZE)\n",
    "        robot.nim = nim\n",
    "        player = 1 - last_player_start\n",
    "        last_player_start = player\n",
    "        while nim:\n",
    "            if player == 0:\n",
    "                ply = OPPONENT_EVAL(nim)\n",
    "            else:\n",
    "                ply = robot.play()\n",
    "            nim.nimming(ply)\n",
    "            player = 1 - player\n",
    "        if player == 0:\n",
    "            won += 1\n",
    "\n",
    "    return won / NUM_MATCHES_EVAL #percentage of match won agaist the opponent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def main():\n",
    "    robot = Agent(None, NUM_MATCHES_TRAINING)\n",
    "\n",
    "    training(robot)\n",
    "    \n",
    "    robot.random_factor = 0 #only exploitation\n",
    "    res = evaluate(robot)\n",
    "    print(res)        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "won in training:  1168\n",
      "0.14\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
